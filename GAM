# =========================================================
# 1. Installazione (eventuale) dei pacchetti necessari
# =========================================================
!pip install --upgrade statsmodels pygam compositions openpyxl

# =========================================================
# 2. Import dei pacchetti
# =========================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as ticker
import io
import contextlib
from scipy.optimize import minimize

from google.colab import files

# Per MANOVA
import statsmodels.multivariate.manova as manova
# Per le regressioni OLS
import statsmodels.api as sm
# Per i GAM
from pygam import LinearGAM, s

# =========================================================
# 3. Caricamento interattivo del file Excel
# =========================================================
uploaded = files.upload()  # Carica il file Excel
file_name = list(uploaded.keys())[0]
print(f"Hai caricato il file: {file_name}")
dati = pd.read_excel(file_name, engine='openpyxl')

# Rinominazione della colonna, se necessaria
if "HB:HV_prod" in dati.columns:
    dati.rename(columns={"HB:HV_prod": "HB_HV_prod"}, inplace=True)

# =========================================================
# 4. Ispezione iniziale del dataset
# =========================================================
print("\nPrime righe del dataset:")
print(dati.head())
print("\nInfo sul dataset:")
print(dati.info())
# VFA: Substrate_Ac, Substrate_Pr, Substrate_Val, Substrate_But
# Risposte: PHA_prod e HB_HV_prod

# =========================================================
# 5. Trasformazione CLR
# =========================================================
vfa = dati[['Substrate_Ac', 'Substrate_Pr', 'Substrate_Val', 'Substrate_But']]

def clr_transform(df):
    """
    Trasforma i dati composizionali in spazio CLR.
    """
    arr = df.values
    g = np.exp(np.mean(np.log(arr), axis=1)).reshape(-1, 1)
    clr_arr = np.log(arr / g)
    return pd.DataFrame(clr_arr, columns=df.columns, index=df.index)

vfa_clr = clr_transform(vfa)
vfa_clr.columns = ['clr_Ac', 'clr_Pr', 'clr_Val', 'clr_But']
dati_clr = pd.concat([vfa_clr, dati[['PHA_prod', 'HB_HV_prod']]], axis=1)
print("\nPrime righe del DataFrame trasformato (CLR):")
print(dati_clr.head())

# =========================================================
# 6. Scatterplot Matrix con range e tick personalizzati
# =========================================================
custom_settings = {
    'clr_Ac':    {'range': (-0.5, 1.5),   'ticks': np.linspace(-0.5, 1.5, 5)},
    'clr_Pr':    {'range': (-1, 1),       'ticks': np.linspace(-1, 1, 5)},
    'clr_Val':   {'range': (-0.5, 1),     'ticks': np.linspace(-0.5, 1, 4)},
    'clr_But':   {'range': (-0.5, 1),     'ticks': np.linspace(-0.5, 1, 4)},
    'PHA_prod':  {'range': (-20, 40),     'ticks': np.linspace(-20, 40, 4)},
    'HB_HV_prod':{'range': (0.25, 3.25),   'ticks': np.linspace(0.25, 3.25, 4)}
}

var_order = list(dati_clr.columns)
g_pair = sns.pairplot(dati_clr, diag_kind='hist')
for i in range(len(var_order)):
    for j in range(len(var_order)):
        ax = g_pair.axes[i, j]
        if ax is not None:
            var_x = var_order[j]
            var_y = var_order[i]
            ax.set_xlim(custom_settings[var_x]['range'])
            ax.set_xticks(custom_settings[var_x]['ticks'])
            ax.set_ylim(custom_settings[var_y]['range'])
            ax.set_yticks(custom_settings[var_y]['ticks'])
plt.show()

# =========================================================
# 7. Calcolo della matrice di correlazione
# =========================================================
corr_matrix = dati_clr.corr()
print("\nMatrice di correlazione (CLR e variabili di risposta):")
print(corr_matrix)

# =========================================================
# 8. Regressioni OLS CON VINCOLO
# =========================================================
X_all = dati_clr[['clr_Ac', 'clr_Pr', 'clr_Val', 'clr_But']]
X_all = sm.add_constant(X_all)
constraint = "clr_Ac + clr_Pr + clr_Val + clr_But = 0"

y_PHA = dati_clr['PHA_prod']
y_HBHV = dati_clr['HB_HV_prod']

try:
    model_PHA = sm.OLS(y_PHA, X_all).fit_constrained(constraint)
    print("\nRisultati OLS per PHA_prod (con vincolo):")
    print(model_PHA.summary())
except AttributeError:
    print("Il metodo fit_constrained non è disponibile. Uso la reparametrizzazione per PHA_prod.")
    X_new = pd.DataFrame({
        'X1': dati_clr['clr_Ac'] - dati_clr['clr_But'],
        'X2': dati_clr['clr_Pr'] - dati_clr['clr_But'],
        'X3': dati_clr['clr_Val'] - dati_clr['clr_But']
    })
    X_new = sm.add_constant(X_new)
    model_PHA = sm.OLS(y_PHA, X_new).fit()
    print("\nRisultati OLS per PHA_prod (reparametrizzati):")
    print(model_PHA.summary())

try:
    model_HBHV = sm.OLS(y_HBHV, X_all).fit_constrained(constraint)
    print("\nRisultati OLS per HB_HV_prod (con vincolo):")
    print(model_HBHV.summary())
except AttributeError:
    print("Il metodo fit_constrained non è disponibile. Uso la reparametrizzazione per HB_HV_prod.")
    X_new = pd.DataFrame({
        'X1': dati_clr['clr_Ac'] - dati_clr['clr_But'],
        'X2': dati_clr['clr_Pr'] - dati_clr['clr_But'],
        'X3': dati_clr['clr_Val'] - dati_clr['clr_But']
    })
    X_new = sm.add_constant(X_new)
    model_HBHV = sm.OLS(y_HBHV, X_new).fit()
    print("\nRisultati OLS per HB_HV_prod (reparametrizzati):")
    print(model_HBHV.summary())

# =========================================================
# 9. Modelli GAM con Grid Search per ottimizzare λ e subplot in colonna
# =========================================================
X_gam_all = dati_clr[['clr_Ac', 'clr_Pr', 'clr_Val', 'clr_But']].values
lam_range = np.logspace(-3, 1, 50)

# GAM per PHA_prod con gridsearch
y_PHA = dati_clr['PHA_prod'].values
gam_PHA = LinearGAM(s(0) + s(1) + s(2) + s(3), fit_intercept=False)
gam_PHA.gridsearch(X_gam_all, y_PHA, lam=lam_range)
print("\n--- GAM per PHA_prod ---")
print("Miglior lambda per PHA_prod:", gam_PHA.lam)
print(gam_PHA.summary())

# GAM per HB_HV_prod con gridsearch
y_HBHV = dati_clr['HB_HV_prod'].values
gam_HBHV = LinearGAM(s(0) + s(1) + s(2) + s(3), fit_intercept=False)
gam_HBHV.gridsearch(X_gam_all, y_HBHV, lam=lam_range)
print("\n--- GAM per HB_HV_prod ---")
print("Miglior lambda per HB_HV_prod:", gam_HBHV.lam)
print(gam_HBHV.summary())

# Verifica del range delle previsioni per il modello GAM HB_HV_prod su clr_Ac
grid = np.linspace(-2, 2, 100)
preds = [gam_HBHV.predict(np.array([[val, 0, 0, 0]]))[0] for val in grid]
print("\nRange delle previsioni (modello HB_HV_prod) per variazioni di clr_Ac:", np.min(preds), np.max(preds))

# =========================================================
# 10. Creazione dei plot parziali dei modelli GAM in un'unica figura (2 righe x 4 colonne)
# =========================================================
fig, axs = plt.subplots(2, 4, figsize=(12, 10))
# Plot parziali per GAM PHA_prod (prima riga)
for i in range(4):
    ax = axs[0, i]
    XX = gam_PHA.generate_X_grid(term=i)
    pdep = gam_PHA.partial_dependence(term=i, X=XX)
    ax.plot(XX[:, i], pdep)
    ax.set_title(f"s({['clr_Ac','clr_Pr','clr_Val','clr_But'][i]})")
    ax.set_xlim(-1, 1)
    ax.set_xticks([-1, -0.5, 0, 0.5, 1])
    ax.set_ylim(-5, 15)
    ax.set_yticks([-5, 0, 5, 10, 15])

# Plot parziali per GAM HB_HV_prod (seconda riga)
for i in range(4):
    ax = axs[1, i]
    XX = gam_HBHV.generate_X_grid(term=i)
    pdep = gam_HBHV.partial_dependence(term=i, X=XX)
    ax.plot(XX[:, i], pdep)
    ax.set_title(f"s({['clr_Ac','clr_Pr','clr_Val','clr_But'][i]})")
    ax.set_xlim(-1, 1)
    ax.set_xticks([-1, -0.5, 0, 0.5, 1])
    ax.set_ylim(-1, 1)
    ax.set_yticks(np.linspace(-1, 1, 5))
plt.tight_layout()
plt.show()

# =========================================================
# 11. Ottimizzazione per massimizzare PHA (senza target HB/HV)
# =========================================================
def objective(clr_vals):
    return -gam_PHA.predict(np.array([clr_vals]))[0]

def constraint_sum(clr_vals):
    return np.sum(clr_vals)

cons = [{'type': 'eq', 'fun': constraint_sum}]
x0 = np.zeros(4)
res = minimize(objective, x0, constraints=cons, bounds=[(-2,2)]*4)
if res.success:
    optimal_clr = res.x
    optimal_pred_PHA = gam_PHA.predict(np.array([optimal_clr]))[0]
    optimal_pred_HBHV = gam_HBHV.predict(np.array([optimal_clr]))[0]
    def clr_to_proportions(clr_vals):
        exp_vals = np.exp(clr_vals)
        return exp_vals / np.sum(exp_vals)
    optimal_proportions = clr_to_proportions(optimal_clr)
    # Calcoliamo le concentrazioni assolute assumendo T = 100
    T = 100
    optimal_concentrations = optimal_proportions * T
    print("\n--- Ottimizzazione per massimizzare PHA ---")
    print("Valori ottimali nello spazio CLR:", optimal_clr)
    print("Proporzioni ottimali (relative ai VFA):", optimal_proportions)
    print("Concentrazioni ottimali (se totale = 100):", optimal_concentrations)
    print("Predicted PHA:", optimal_pred_PHA)
    print("Predicted HB/HV:", optimal_pred_HBHV)
else:
    print("Ottimizzazione fallita:", res.message)

# =========================================================
# 12. 3D Surface plots (Ac & Pr) e (Pr & Val) per PHA_prod e HB_HV_prod
# =========================================================

T = 100
baseline_conc = optimal_proportions * T
epsilon = 1e-6

var_to_index = {"Ac": 0, "Pr": 1, "Val": 2, "But": 3}

vfa_labels = {
    "Ac": "Ac (%)",
    "Pr": "Pr (%)",
    "Val": "Val (%)",
    "But": "But (%)"
}

def compute_gam_response(x_val, y_val, x_var, y_var, model, baseline_conc, T=50):
    idx_x = var_to_index[x_var]
    idx_y = var_to_index[y_var]

    sum_xy = x_val + y_val
    remain = T - sum_xy
    if remain < 0:
        return np.nan

    new_conc = np.zeros(4)
    new_conc[idx_x] = x_val
    new_conc[idx_y] = y_val

    baseline_other_sum = (
        np.sum(baseline_conc) - (baseline_conc[idx_x] + baseline_conc[idx_y])
    )
    for j in range(4):
        if j not in [idx_x, idx_y]:
            new_conc[j] = baseline_conc[j] / baseline_other_sum * remain

    new_prop = new_conc / T
    new_prop = np.maximum(new_prop, epsilon)
    new_prop = new_prop / np.sum(new_prop)
    new_clr = np.log(new_prop) - np.mean(np.log(new_prop))
    return model.predict(np.array([new_clr]))[0]

def create_3d_surface(ax, x_var, y_var, model, zlabel, title_label,
                      x_min, x_max, y_min, y_max, n_points=50,
                      axis_label_size=14,
                      tick_label_size=12,
                      title_size=16):
    X_range = np.linspace(x_min, x_max, n_points)
    Y_range = np.linspace(y_min, y_max, n_points)
    X, Y = np.meshgrid(X_range, Y_range)
    Z = np.zeros_like(X)

    for i in range(n_points):
        for j in range(n_points):
            Z[i, j] = compute_gam_response(
                X[i, j], Y[i, j],
                x_var, y_var,
                model,
                baseline_conc,
                T
            )

    surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.8)

    ax.set_xlim(x_min, x_max)
    ax.set_ylim(y_min, y_max)
    ax.set_xticks(np.linspace(x_min, x_max, 6))
    ax.set_yticks(np.linspace(y_min, y_max, 6))

    if "PHA" in zlabel:
        ax.set_zlim(10, 35)
        ax.set_zticks(np.linspace(10, 35, 6))
    else:
        ax.set_zlim(1, 3.5)
        ax.set_zticks(np.linspace(1, 3.5, 6))

    ax.set_xlabel(vfa_labels[x_var], fontsize=axis_label_size, color='black')
    ax.set_ylabel(vfa_labels[y_var], fontsize=axis_label_size, color='black')
    ax.set_zlabel(zlabel, fontsize=axis_label_size, color='black')
    ax.set_title(title_label, loc='left', fontweight='bold', fontsize=title_size)

    ax.tick_params(axis='x', labelsize=tick_label_size, colors='black')
    ax.tick_params(axis='y', labelsize=tick_label_size, colors='black')
    ax.tick_params(axis='z', labelsize=tick_label_size, colors='black')

# Creazione della figura (24x24 pollici)
fig = plt.figure(figsize=(24, 24))
subplot_labels = [r"$\mathbf{(A)}$", r"$\mathbf{(B)}$", r"$\mathbf{(C)}$", r"$\mathbf{(D)}$"]

# (A) - PHA_prod, (x,y) = (Ac, Pr)
axA = fig.add_subplot(2, 2, 1, projection='3d')
create_3d_surface(
    axA,
    x_var="Ac",
    y_var="Pr",
    model=gam_PHA,
    zlabel=r"PHA$_{prod}$",
    title_label=subplot_labels[0],
    x_min=10, x_max=20,
    y_min=5,  y_max=15
)

# (B) - HB/HV_prod, (x,y) = (Ac, Pr)
axB = fig.add_subplot(2, 2, 2, projection='3d')
create_3d_surface(
    axB,
    x_var="Ac",
    y_var="Pr",
    model=gam_HBHV,
    zlabel=r"HB:HV$_{prod}$",
    title_label=subplot_labels[1],
    x_min=10, x_max=20,
    y_min=5,  y_max=15
)

# (C) - PHA_prod, **(x,y) = (Pr, Val)** con range [10,20] su entrambi
axC = fig.add_subplot(2, 2, 3, projection='3d')
create_3d_surface(
    axC,
    x_var="Pr",   # <--- Cambiato in "Pr"
    y_var="Val",  # <--- Cambiato in "Val"
    model=gam_PHA,
    zlabel=r"PHA$_{prod}$",
    title_label=subplot_labels[2],
    x_min=10, x_max=20,  # <--- Ranges [10, 20]
    y_min=5, y_max=15
)

# (D) - HB/HV_prod, **(x,y) = (Pr, Val)** con range [10,20] su entrambi
axD = fig.add_subplot(2, 2, 4, projection='3d')
create_3d_surface(
    axD,
    x_var="Pr",    # <--- Cambiato in "Pr"
    y_var="Val",   # <--- Cambiato in "Val"
    model=gam_HBHV,
    zlabel=r"HB:HV$_{prod}$",
    title_label=subplot_labels[3],
    x_min=10, x_max=20,  # <--- Ranges [10, 20]
    y_min=5, y_max=15
)

# Margini e spaziatura
plt.subplots_adjust(
    left=0.05,  right=0.95,
    bottom=0.05, top=0.95,
    wspace=0.3,  hspace=0.3
)

fig.savefig("3d_plot.png", dpi=300, bbox_inches=None, pad_inches=0.5)
files.download("3d_plot.png")
plt.show()



# =========================================================
# 13. Sensitivity Analysis con 4 subplot (gruppi "Ac & Pr" e "But & Val")
# per le risposte: PHA_prod (prima riga, y=[0,40]) e HB/HV_prod (seconda riga, y=[0,4])
# Range di sensitivity: 10-60
# =========================================================

T = 100  # Totale delle concentrazioni
baseline_conc = optimal_proportions * T  # Concentrazioni ottimali di baseline
epsilon = 1e-6  # Valore minimo per evitare log(0)

# Definiamo i gruppi di variabili e mappa per gli indici
group1 = ["Ac", "Pr"]
group2 = ["But", "Val"]
var_to_index = {"Ac": 0, "Pr": 1, "Val": 2, "But": 3}

# Palette "colorblind" per 4 colori
colors = sns.color_palette("colorblind", 4)

# Range e tick per l'asse x e y
candidate_conc_vals = np.linspace(10, 60, 500)
xticks = np.linspace(10, 60, 6)
pha_yticks = np.linspace(0, 40, 5)
hbhv_yticks = np.linspace(0, 4, 5)

# Creazione della figura con 2 righe x 2 colonne, stessa dimensione (14x10)
fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))
subplot_labels = [r"$\mathbf{(A)}$", r"$\mathbf{(B)}$", r"$\mathbf{(C)}$", r"$\mathbf{(D)}$"]

for row, (response_name, gam_model) in enumerate([("PHA_prod", gam_PHA), ("HB_HV_prod", gam_HBHV)]):
    for col, group in enumerate([group1, group2]):
        ax = axs[row, col]
        for var in group:
            idx = var_to_index[var]
            preds = []
            for conc_val in candidate_conc_vals:
                new_conc = np.zeros(4)
                new_conc[idx] = conc_val
                remaining = T - conc_val
                baseline_other_sum = np.sum(baseline_conc) - baseline_conc[idx]
                for j in range(4):
                    if j != idx:
                        new_conc[j] = baseline_conc[j] / baseline_other_sum * remaining
                new_prop = new_conc / T
                new_prop = np.maximum(new_prop, epsilon)
                new_prop = new_prop / np.sum(new_prop)
                new_clr = np.log(new_prop) - np.mean(np.log(new_prop))
                pred = gam_model.predict(np.array([new_clr]))[0]
                preds.append(pred)
            ax.plot(candidate_conc_vals, preds, label=var, color=colors[var_to_index[var]])
        ax.set_xlim([10, 60])
        ax.set_xticks(xticks)
        ax.set_xlabel(r"Concentration ($C_{mmol}\ L^{-1}$)", color='black')
        if response_name == "PHA_prod":
            ax.set_ylim([0, 40])
            ax.set_yticks(pha_yticks)
            ax.set_ylabel(r"$PHA_{prod}$", color='black')
        else:
            ax.set_ylim([0, 4])
            ax.set_yticks(hbhv_yticks)
            ax.set_ylabel(r"$HB:HV_{prod}$", color='black')
        ax.tick_params(axis='x', colors='black')
        ax.tick_params(axis='y', colors='black')
        ax.legend()
        subplot_index = row * 2 + col
        ax.text(-0.15, 1.1, subplot_labels[subplot_index], transform=ax.transAxes,
                fontsize=16, fontweight='bold', va='top', ha='left', color='black')
        # Non si imposta un titolo individuale qui

plt.tight_layout()
plt.show()


# =========================================================
# 14. Dettaglio dell'ottimo: variazione ±10% attorno all'ottimo
# =========================================================
# Per ciascun VFA (Ac, Pr, Val, But) esaminiamo come variano le risposte attorno all’ottimo,
# esprimendo la variazione in termini percentuali (da -10% a +10%).
T = 100  # Totale delle concentrazioni
epsilon = 1e-6

variables = ['Ac', 'Pr', 'Val', 'But']
var_to_index = {"Ac": 0, "Pr": 1, "Val": 2, "But": 3}

# Definiamo i tick per l'asse x in termini percentuali
pct_ticks = [-0.10, -0.05, 0, 0.05, 0.10]
pct_ticklabels = ['-10%', '-5%', '0%', '5%', '10%']

# Creazione della figura con 4 subplot (2x2)
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
subplot_labels = ["(A)", "(B)", "(C)", "(D)"]

# Creiamo due handle personalizzati per la legenda globale
import matplotlib.lines as mlines
handle_PHA = mlines.Line2D([], [], color='b', label=r'$PHA_{prod}$')
handle_HBHV = mlines.Line2D([], [], color='r', label=r'$HB:HV_{prod}$')

for i, var in enumerate(variables):
    idx = var_to_index[var]
    opt_conc = optimal_concentrations[idx]
    # Definiamo il range percentuale: da -10% a +10%
    candidate_pct = np.linspace(-0.10, 0.10, 50)
    preds_PHA = []
    preds_HBHV = []

    for pct in candidate_pct:
        candidate_conc = opt_conc * (1 + pct)
        new_conc = np.zeros(4)
        new_conc[idx] = candidate_conc
        remaining = T - candidate_conc

        baseline_other_sum = np.sum(optimal_concentrations) - opt_conc
        for j in range(4):
            if j != idx:
                new_conc[j] = optimal_concentrations[j] / baseline_other_sum * remaining

        new_prop = new_conc / T
        new_prop = np.maximum(new_prop, epsilon)
        new_prop = new_prop / np.sum(new_prop)
        new_clr = np.log(new_prop) - np.mean(np.log(new_prop))

        pred_PHA = gam_PHA.predict(np.array([new_clr]))[0]
        pred_HBHV = gam_HBHV.predict(np.array([new_clr]))[0]
        preds_PHA.append(pred_PHA)
        preds_HBHV.append(pred_HBHV)

    ax = axs[i//2, i % 2]
    # Plot della linea per PHA in blu
    ax.plot(candidate_pct, preds_PHA, 'b-', label=r'$PHA_{prod}$')
    # Impostazione asse x con label specifico: ΔAc, ΔPr, etc.
    ax.set_xlabel(r"$\Delta " + var + r"\ (\%)$", color='black')
    ax.tick_params(axis='x', colors='black')
    ax.set_xlim([-0.10, 0.10])
    ax.set_xticks(pct_ticks)
    ax.set_xticklabels(pct_ticklabels, color='black')

    # Impostiamo sempre il label del primo asse y a "PHA_prod"
    ax.set_ylabel(r"$PHA_{prod}$", color='black')
    ax.tick_params(axis='y', colors='black')
    ax.set_ylim([0, 40])
    ax.set_yticks(np.linspace(0, 40, 5))

    # Creazione dell'asse secondario per HB:HV_prod con label sempre visibile
    ax2 = ax.twinx()
    ax2.plot(candidate_pct, preds_HBHV, 'r-', label=r'$HB:HV_{prod}$')
    ax2.set_ylim([0, 4])
    ax2.set_yticks(np.linspace(0, 4, 5))
    ax2.set_ylabel(r"$HB:HV_{prod}$", color='black')
    ax2.tick_params(axis='y', colors='black')

    # Aggiungiamo l'etichetta del subplot (A), (B), ... esterna all'area del grafico
    ax.annotate(subplot_labels[i], xy=(0, 1), xytext=(-40, 10),
                xycoords='axes fraction', textcoords='offset points',
                fontsize=16, fontweight='bold', color='black')

plt.tight_layout(rect=[0, 0.1, 1, 1])  # Lasciamo spazio in basso per la legenda
# Aggiungiamo una legenda globale in basso centrata
fig.legend(handles=[handle_PHA, handle_HBHV], loc='lower center', ncol=2, fontsize=12)
plt.show()

# =========================================================
# 15. Calcolo e salvataggio delle predizioni GAM per i dati originali
#     (NUOVA SEZIONE RICHIESTA)
# =========================================================

# Creiamo una copia del DataFrame originale per aggiungere le predizioni
dati_predictions = dati.copy()

predicted_PHA_list = []
predicted_HBHV_list = []

# Funzione di supporto: calcola il CLR di un vettore 4D di VFA
def single_clr_transform(vfa_array):
    # vfa_array = [Ac, Pr, Val, But]
    g_val = np.exp(np.mean(np.log(vfa_array)))
    return np.log(vfa_array / g_val)

# Iteriamo su ogni riga del dataset originale, calcolando la predizione
for idx, row in dati_predictions.iterrows():
    ac_val  = row['Substrate_Ac']
    pr_val  = row['Substrate_Pr']
    val_val = row['Substrate_Val']
    but_val = row['Substrate_But']

    # Costruiamo il vettore delle concentrazioni
    vfa_array = np.array([ac_val, pr_val, val_val, but_val], dtype=float)

    # Calcoliamo il CLR
    clr_values = single_clr_transform(vfa_array)

    # Usiamo i modelli GAM per predire
    pha_pred  = gam_PHA.predict(clr_values.reshape(1, -1))[0]
    hbhv_pred = gam_HBHV.predict(clr_values.reshape(1, -1))[0]

    predicted_PHA_list.append(pha_pred)
    predicted_HBHV_list.append(hbhv_pred)

# Aggiungiamo le colonne di predizione al DataFrame
dati_predictions['Predicted_PHA'] = predicted_PHA_list
dati_predictions['Predicted_HB_HV'] = predicted_HBHV_list

# =========================================================
# 16. Salvataggio finale dei risultati in un file Excel e download
# =========================================================

writer = pd.ExcelWriter("results.xlsx", engine="openpyxl")
corr_matrix.to_excel(writer, sheet_name="Correlation_Matrix", index=True)

ols_pha_text = model_PHA.summary().as_text()
ols_pha_df = pd.DataFrame({"OLS_PHA_Summary": ols_pha_text.splitlines()})
ols_pha_df.to_excel(writer, sheet_name="OLS_PHA", index=False)

ols_hbhv_text = model_HBHV.summary().as_text()
ols_hbhv_df = pd.DataFrame({"OLS_HBHV_Summary": ols_hbhv_text.splitlines()})
ols_hbhv_df.to_excel(writer, sheet_name="OLS_HBHV", index=False)

sio_pha = io.StringIO()
with contextlib.redirect_stdout(sio_pha):
    gam_PHA.summary()
gam_pha_text = sio_pha.getvalue()
gam_pha_df = pd.DataFrame({"GAM_PHA_Summary": gam_pha_text.splitlines()})
gam_pha_df.to_excel(writer, sheet_name="GAM_PHA", index=False)

sio_hbhv = io.StringIO()
with contextlib.redirect_stdout(sio_hbhv):
    gam_HBHV.summary()
gam_hbhv_text = sio_hbhv.getvalue()
gam_hbhv_df = pd.DataFrame({"GAM_HBHV_Summary": gam_hbhv_text.splitlines()})
gam_hbhv_df.to_excel(writer, sheet_name="GAM_HBHV", index=False)

# Salviamo i risultati delle predizioni su un nuovo foglio
dati_predictions.to_excel(writer, sheet_name="Predictions", index=False)

writer.close()
files.download("results.xlsx")

print("\nWorkflow completato con successo!")
